背景：  
在建模的时候，看别人代码的时候经常遇到：
> (1) 训练集、验证集、测试集   
> (2) 训练集、测试集   
> (3) 交叉验证  
……  

为什么划分方法不一样？为什么很多人直接不要验证集，只分训练集、测试集？交叉验证里有验证集？验证集跟测试集有什么区别？？？    

>
## 训练集training set 验证集validation set和测试集test set  
推荐去看吴恩达的课（有好的资料也欢迎推荐哦）：https://www.bilibili.com/video/BV164411b7dx?p=60    
打个比方：训练集有点学生平时学的课本，而验证集就像月考，测试集就像期末考。  
> 平时努力学习课本知识(训练);  
> 月考后针对错题，针对性去理解做的的原因，改错(根据评判标准去调参);  
> 最后期末考来了，考完就这样了，你无法改变啥(只做一次测试，不回去改参数，不拿测试集的数据去影响训练集和验证集)。  

>
严格意义上来说，建模需要分三块数据，出来的研究结果才更严谨。虽然分分钟在测试集里，验证误差变大了，但是比仅在验证集里拿个小泛化误差更具说服力。毕竟，这才是真正的泛化能力。超参是用验证集调出来的，肯定是根据验证误差小而选出来的，而以这个小验证误差来说模型性能高，在严谨性上还是不够的。所以，有测试集才更科学严谨。还有，测试集仅用来测一次性能，即使性能差，也不要回去调参，回去调参就有点作弊内意思了！！！  

>     
一般划分比例是：训练集：验证集：测试集 = 6:2:2。    
> 如果数据是数万级，可以直接用此比例   
> 如果数据是百万级别的，可以适当降低验证集和测试集的比例    
> 如果模型需要调的超参比较少，数据也可以在训练集上倾斜多一点      

>
但是，我们经常遇到小数据，几百、几千。如果数据还要分成三部分，建模结果似乎不太可靠，带有相对较多的随机性，害怕拿去用就翻车。这时候用交叉验证可能更可靠。毕竟不是大数据量，计算消耗的时间相对没那么可怕，而且训练集有一定的数量保障（相对于再划分一部分数据为验证集）。    

>
交叉验证举例（拿鸢尾花数据来做）：   
```python
from sklearn import datasets
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier  # 用KNN来做预测，其中的N为超参
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['SimHei']

iris = datasets.load_iris()	  # 下载数据
X = iris.data
Y = iris.target
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.3, random_state=248)
k_range = range(1, 51)  # k值取值范围
cv_scores = []   # 放交叉验证的结果
for n in k_range:
    knn = KNeighborsClassifier(n)   # knn模型
    # 做十折交叉验证，选择accuracy准确度为评价指标
    scores = cross_val_score(knn, train_X, train_Y, cv=10, scoring='accuracy')
    # print(scores)
    cv_scores.append(scores.mean())  # 在当前n值下，取9个scores的平均值作为评判标准
plt.plot(k_range, cv_scores)  # 做二维图看分类数对模型性能的影响
plt.xlabel('k值')
plt.ylabel('Accuracy')
plt.show()
```
![](https://ftp.bmp.ovh/imgs/2020/11/8fd991b1a42a4f86.png)  
从图片看出，当k取6时，准确度是比较高的，这时候，就通过交叉验证确定了超参。接下来，将模型应用到测试集里，看模型的泛化能力是怎样的。
```python
best_knn = KNeighborsClassifier(n_neighbors=6)	# 将最优的k=6传入模型
best_knn.fit(train_X, train_Y)			# 训练模型
print(best_knn.score(test_X, test_Y)) 
```
输出结果：0.9555555555555556  
至此，就完成了整个大框的流程。  
后记：  
> 本人行业经验还不是很够，在小数据里，更倾向于用交叉验证来选取超参。
> 注意，在划分数据集的时候，可能存在类别不均衡问题，可采用分层抽样解决。而且要尽量保证划分前后数据的分布一致  
> ……其他的后面再record  
![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1606114393160&di=5a9d94aff46350822135fef803a60071&imgtype=0&src=http%3A%2F%2Fimg.kuai8.com%2Fattaches%2Fnews%2Fimage%2F20190227%2F201902271027482961.jpg)

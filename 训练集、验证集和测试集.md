背景：  
在建模的时候，看别人代码的时候经常遇到：
- (1) 训练集、验证集、测试集  
- (2) 训练集、测试集  
- (3) 交叉验证
……
为什么划分方法不一样？为什么很多人直接不要验证集，只分训练集、测试集？交叉验证里有验证集？验证集跟测试集有什么区别？？？    
>
## 训练集training set 验证集validation set和测试集test set  
打个比方：训练集有点学生平时学的课本，而验证集就像月考，测试集就像期末考。平时努力学习课本知识，月考后针对错题，针对性去理解做的的原因，改错，做好准备。最后期末考来了，考完就这样了，你无法改变啥。  
严格意义上来说，建模需要这三块数据，出来的研究结果更严谨。虽然分分钟在测试集里，验证误差变大了，但是比仅在验证集里拿个小泛化误差更具说服力。毕竟，超参是用验证集调出来的，肯定是根据验证误差小而选出来的，而以这个小验证误差来说模型性能高，在严谨性上还是不够的。所以，有测试集才更科学严谨。还有，测试集仅用来测一次性能，即使性能差，也不要回去调参！！！ >     
一般划分比例是：训练集：验证集：测试集 = 6:2:2。  
- 如果数据是数万级，可以直接用此比例  
- 如果数据是百万级别的，可以适当降低验证集和测试集的比例  
- 如果模型需要调的超参比较少，数据也可以在训练集上倾斜多一点    
https://www.bilibili.com/video/BV164411b7dx?p=60  
>
但是，我们经常遇到小数据，几百、几千。如果数据还要分成三部分，建模结果似乎不太可靠，带有相对较多的随机性，害怕拿去用就翻车。这时候用交叉验证可能更可靠。毕竟不是大数据量，计算消耗的时间相对没那么可怕，而且训练集有一定的数量保障（相对于再划分一部分数据为验证集）。    
>
交叉验证举例（拿鸢尾花数据来做）：   
'''python
from sklearn import datasets	
from sklearn.model_selection import train_test_split,cross_val_score	
from sklearn.neighbors import KNeighborsClassifier  # 用KNN来做预测，其中的N为超参
import matplotlib.pyplot as plt
iris = datasets.load_iris()	  # 下载数据	
X = iris.data 		
y = iris.target 		
train_X,test_X,train_y,test_y = train_test_split(X,y,test_size=1/3,random_state=3)	#这里划分数据以1/3的来划分 训练集训练结果 测试集测试结果
k_range = range(1,31)
cv_scores = []		#用来放每个模型的结果值
for n in k_range:
    knn = KNeighborsClassifier(n)   #knn模型，这里一个超参数可以做预测，当多个超参数时需要使用另一种方法GridSearchCV
    scores = cross_val_score(knn,train_X,train_y,cv=10,scoring='accuracy')  #cv：选择每次测试折数  accuracy：评价指标是准确度,可以省略使用默认值，具体使用参考下面。
    cv_scores.append(scores.mean())
plt.plot(k_range,cv_scores)
plt.xlabel('K值')
plt.ylabel('Accuracy')		#通过图像选择最好的参数
plt.show()
best_knn = KNeighborsClassifier(n_neighbors=3)	# 选择最优的K=3传入模型
best_knn.fit(train_X,train_y)			#训练模型
print(best_knn.score(test_X,test_y))	
```

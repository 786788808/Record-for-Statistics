# 主成分分析法 PCA (Principal components analysis)
提到 PCA，第一反应就是降维。  
对这块涉及的很多数学概念遗忘了，该篇来整理一下思路，涉及的数学知识后面再慢慢补。不做单纯的公式推断，因为很容易忘。  
>
### 目录：
- PCA 概念
- 算法优缺点
- sklearn 用法

### 一. PCA 概念
PCA, 主成分分析法，用较少的变量去解释原始数据中的大部分变量，即将许多相关性很高的变量转化成彼此相互独立或不想关的变量。  
它是一种应用广泛的数据降维算法(无监督)，也可以用于提取数据的主要特征。   
它通过构建新坐标轴，将原有的 n 维数据降成新的 n' 维(n'<n, n'维特征叫做主成分，且正交，也就是互不相关)。可以理解为 PCA 就是要找到一个新的超平面，让样本点到这个超平面的距离足够近，或者说样本点在这个超平面的投影尽可能地分开。    
>
实现步骤：  
#### 理解一：逐一选取方差最大方向法  
PCA 要找一组相互正交的坐标轴，来表示原有的特征。    
算法依次找到合适的轴。  
首先，第一个轴方向会选择原始数据中方差最大的方向(方差即不确定性，不确定性即信息。对一组样本来说，方差越大，代表样本中含有的信息越多。因此，我们可将方差看作信息量的一个度量)；    
接着，第二个轴选取，需要在与第一个轴正交的平面中选择方差最大的方向；   
然后，第三个轴选取，在与第一、第二正交的平面中选择方差最大的方向；   
重复以上步骤，直至找到 n 个坐标轴。    
在这个过程中，大部分的方差都会包含在前面的 n' 个坐标轴里，剩下的坐标轴包含的方差接近 0 。我们只保留前面的 n' 个含有大部分方差的坐标轴，忽略剩下的坐标轴，以此留下 n' 个主成分，实现对数据的降维。  这其中存在一定的信息丢失问题，但是总体上来说，是对建模有好处的(大多数情况下)。    
新的特征有更好的区分度，也可理解为变异或方差更大。  
>
#### 理解二：直接选取最大 n' 个特征值 
步骤：  
- 对所有样本进行中心化
- 计算样本的协方差矩阵
- 对协方差矩阵做特征值分解
- 去最大的n'个特征值所对应的特征向量

**注意：**  
- 在实际应用中，常用SVD奇异值分解，而非上述的协方差矩阵的特征值分解。  
- 做PCA前要做标准化，因为在后续计算方差时，如果某个特征的数值范围较大，其方差也会相对较大。标准化后，才能让各特征有平等的位置，让数据不偏倚。  
>

### 二. 算法优缺点：

#### 2.1 优点：  
- 缓解维度灾难带来的问题(对于涉及计算距离的算法，降维让距离更有实际意义；减少计算开销)  
- 各主成分之间正交，互不相干，可解决原有数据的特征相关问题  
- 降低噪声影响。小特征值对应的特征向量往往与噪声有关，舍弃它们舍弃在一定程度上起到降噪的作用  
>
#### 2.2 缺点：
- 主成分的含义具有模糊性，建模后难以解释。如果后续要解释模型中每个特征的具体含义，考虑换种方法吧。  
- 可能舍弃掉重要信息，导致过拟合。方差小的非主成分在训练集作用不大，但可能其在测试集、实际数据中起重要作用，在训练集觉得他们的去留，可能最后模型过拟合。 
>
>
### 三. sklearn用法
用鸢尾花数据集做示例：  
可设置参数，第一种设置保留主成分个数，第二种设置方差解释百分比：    
```
from sklearn.decomposition import PCA
from sklearn import datasets

iris_df = datasets.load_iris()
X = iris_df.data
Y = iris_df.target
print('原始数据集大小：', X.shape)
print('1. 参数设置主成分个数：')
pca_1 = PCA(n_components=3)
pca_1.fit(X)
print('解释方法比例：', pca_1.explained_variance_ratio_)
print('方差：', pca_1.explained_variance_)
print('\n')
print('2. 参数设置主成分方差解释比例：')
pca_2 = PCA(n_components=0.95)
pca_2.fit(X)
print('解释方法比例：', pca_2.explained_variance_ratio_)
print('方差：', pca_2.explained_variance_)
```
输出结果：  
![](https://sc01.alicdn.com/kf/U82a3f027e6c94431b3a20aeaa96d547bh.jpg)  

>
资料参考：  
[刘建平blog](https://www.cnblogs.com/pinard/p/6239403.html)  
https://blog.csdn.net/program_developer/article/details/80632779  
https://www.zhihu.com/question/41120789?sort=created  



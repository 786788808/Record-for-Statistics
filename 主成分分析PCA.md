# 主成分分析法 PCA (Principal components analysis)
提到 PCA，第一反应就是做降维。  
对这块涉及的很多数学概念遗忘了，该篇来整理一下思路，涉及的数学知识后面再慢慢补。不做单纯的公式推断，因为很容易忘。  

### 目录： 
- PCA 概念
- 算法优缺点

### 一. PCA 概念 
PCA, 主成分分析法，一种应用广泛的数据降维算法(无监督)，也可以用于提取数据的主要特征。它通过构建新坐标轴，将原有的 n 维数据降成新的 n' 维(n'<n, n'维特征叫做主成分，且正交，也就是互不相关)。可以理解为 PCA 就是要找到一个新的超平面，让样本点到这个超平面的距离足够近，或者说样本点在这个超平面的投影尽可能地分开。    
实现步骤：  
PCA 要找一组相互正交的坐标轴，来表示原有的特征。    
算法依次找到合适的轴。  
首先，第一个轴方向会选择原始数据中方差最大的方向；    
接着，第二个轴选取，需要在与第一个轴正交的平面中选择方差最大的方向；  
然后，第三个轴选取，在与第一、第二正交的平面中选择方差最大的方向；  
重复以上步骤，直至找到 n 个坐标轴。    
在这个过程中，大部分的方差都会包含在前面的 n' 个坐标轴里，剩下的坐标轴包含的方差接近 0 。我们只保留前面的 n' 个含有大部分方差的坐标轴，忽略剩下的坐标轴，以此留下 n' 个主成分，实现对数据的降维。  
这其中存在一定的信息丢失问题，但是总体上来说，是对建模有好处的(大多数情况下)。    
新的特征有更好的区分度，也可理解为变异或方差更大。  
>

### 二. 算法优缺点：
- 缓解维度灾难：PCA 算法通过舍去一部分信息之后能使得样本的采样密度增大（因为维数降低了），这是缓解维度灾难的重要手段；
降噪：当数据受到噪声影响时，最小特征值对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到降噪的效果；
过拟合：PCA 保留了主要信息，但这个主要信息只是针对训练集的，而且这个主要信息未必是重要信息。有可能舍弃了一些看似无用的信息，但是这些看似无用的信息恰好是重要信息，只是在训练集上没有很大的表现，所以 PCA 也可能加剧了过拟合；
特征独立：PCA 不仅将数据压缩到低维，它也使得降维之后的数据各特征相互独立；


优缺点：
优点：  
- 缓解维度灾难带来的问题(对于涉及计算距离的算法，降维让距离更有实际意义；减少计算开销)
- 各主成分之间正交，互不相干，可解决原有数据的特征相关问题
- 
- 
- 
- 去除噪声，
>

缺点：
- 主成分的含义具有模糊性，建模后难以解释。如果后续要解释模型中每个特征的含义，考虑换种方法吧。  
- 可能舍弃掉重要信息。方差小的非主成分在训练集作用不大，但可能其在测试集、实际数据中起重要作用，在训练集觉得他们的去留，可能最后模型过拟合。  
- 


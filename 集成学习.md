## 集成学习 Ensemble Learning
集成学习不是单独的一个机器学习算法，其按照不同的思路来组合多个弱学习器来完成学习任务。  
![](https://ae03.alicdn.com/kf/U401735f481d1477ca0b0a31448a36d03O.jpg)  
现有三种常见的集成框架：：Bagging，Boosting和Stacking.  

### Bagging
先补充一个抽样概念：
- Bootstrap自助法
> 一种有放回的抽样方法，它是非参数统计中一种重要的估计统计量方差进而进行区间估计的统计方法。在小样本时效果很好。    
> 过程：  
> 给定包含m个样本的原始数据集D，现要对它进行采样产生数据集D'：每次随机地从D中抽取一个样本，放进新数据集D'，然后再将该样本放回到初始样本D中，使得该样本后面仍有可能被抽取。重复以上抽取动作，直至新数据集D'中包含m个样本。  
> 在这个过程中，部分样本会被重复抽取，而部分不出现。可以做估计：样本在m次采样中始终不被采用的概率是(1-1/m)^m。取极限可约等于0.368，即可认为数据集D中36.8%的样本始终不会被抽到,有63.2%的样本会出现在新数据集中。  

Bagging实现流程：  
采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器经一定的结合策略形成一个强学习器。    
![](https://ae02.alicdn.com/kf/U50aa77d77032489c8046beb127e0e46b6.jpg)  





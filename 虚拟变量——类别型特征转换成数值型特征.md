### 背景：  
建模过程中，经常会看到类别型变量，比如：性别：男女；电脑品牌：acer、联想、Mac；产品颜色：红黄蓝……某些模型会要求全数值型变量，比如Kmeans、逻辑回归、支持向量机，在这些模型里，
类别型变量必须转换成数值型变量才能正常计算。只有决策树等少数模型能直接处理字符串形式的输入。对于决策树来说，one-hot的本质是增加树的深度。    
做哑变量处理后，如果数据很高维，需要配合特征选择来降低维度。比如KNN算法中，用到欧氏距离来度量距离，但是高维空间下，距离度量失效。  
常见的处理方法：  
- 序号编码(Ordinary Encoding) 
- 独热编码
- 二进制编码
- get_dummy

### 一.pd.get_dummies() 一步搞定
#### (1.1) 用法
语法：pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)
[官网文档](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)  
输入：array-like, Series, or DataFrame(可由多种格式的数据输入，方便)
输出：DataFrame
主要参数：
> data : array-like, Series, or DataFrame
> prefix : 给输出的列添加前缀，如prefix="A",输出的列会显示类似
> prefix_sep : 设置前缀跟分类的分隔符sepration，默认是下划线"_"
#### (1.2) 举个栗子：  
```
import pandas as pd
data = pd.DataFrame({'学号':[202001,202002,202003,202004],
                    '性别':['男','女','女','男'],
                    '学历':['本科','硕士','专科','本科'],
                    '选修课':['篮球','排球','排球','网球']})
print(data)
print(pd.get_dummies(data))
```
![](https://ftp.bmp.ovh/imgs/2020/12/9af84c015c56a87b.png)  
![](https://ftp.bmp.ovh/imgs/2020/12/95682a5631d22266.png)  
**在应用中，假设特征A存在k个分类，保留k-1列即可，因为有多重共线性问题。**  

### 二.One-Hot Encoding 独热编码
sklearn.preprocessing.OneHotEncoder(n_values=None, categorical_features=None, categories=None, sparse=True, dtype=<class ‘numpy.float64’>, handle_unknown=’error’)
[官网文档](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)  
**该转换器的输入应为整数或字符串形式的数组**,如果输入文本，会报错。对于文本，应该转换成数字。   
```
from sklearn.preprocessing import OneHotEncoder
one_hot_encod = OneHotEncoder()
one_hot_encod.fit(data)
print('One-Hot Encoding编码：')
print('=='*14)
print(one_hot_encod.fit_transform(data.iloc[:,1:]).toarray()) 
```
![](https://ftp.bmp.ovh/imgs/2020/12/20ae37153009521b.png)  


![](https://ftp.bmp.ovh/imgs/2020/12/1187054a9d252826.png)   
## 基于密度的聚类算法DBSCAN(Density-Based Spatial Clustering of Applications with Noise)
本文介绍基于密度的聚类算法，这类算法假定聚类结构能通过样本分布的紧密程度确定。  
通常情况下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并给予可连接样本不断扩展聚类簇以获得最终的聚类结果。  
>
### 一. DBSCAN基础概念及原理步骤：  
DBSCAN(具有噪声的基于密度的聚类方法)是其中一种基于密度的聚类算法,  它基于一组邻域参数参数(ϵ, MinPts)来刻画样本分布的紧密程度。
#### (1.1) 基本概念：  
给定数据集D={x1, x2, x3, ……, xm},
- ϵ-邻域：对于xj∈D，其ϵ-邻域包含样本集D中与xj的距离不大于ϵ的子样本集，即Nϵ(xj)={xi∈D|dist(xi,xj)≤ϵ}。定义点xj领域里的其他其他点的个数记为|Nϵ(xj)|　(注：默认选用欧式距离来作为dist()函数)   
- 核心对象：对于任一样本xj∈D，如果其ϵ-邻域对应的Nϵ(xj)至少包含MinPts个样本，即如果|Nϵ(xj)|≥MinPts，则xj是核心对象。(可以将ϵ理解为半径，MinPts理解为点周围的点个数(理论值)。以某个点为中心画个圆，如果圈里面的数量达标，它就是核心对象)  
- 密度直达：如果xj位于xi的ϵ-邻域中，且xi是核心对象，则称xj由xi密度直达。(注意位置，反过来说不一定对）   
- 密度可达：对于xi和xj, 若存在样本序列p1,p2,...,pn,其中，p1=xi,pn=xj, 且p(i+1)由pi密度直达，则称xj由xi密度可达。(注：序列中的p1,p2,...,p(n-1)均为核心对象，因为要满足密度直达必须要是核心对象，对pn而言，其还不用是核心对象，因为他是最后一个。密度直达满足直递性，但不满足对称性)   
- 密度相连：对于xi和xj,如果存在核心对象xk，使xi和xj均由xk密度可达，则称xi和xj密度相连。(密度相连关系是满足对称性)    
举例加深理解：  
![](https://ftp.bmp.ovh/imgs/2020/12/ebfceb56502ca7ac.png)    
上图中，我们先指定ϵ(圆的半径), MinPts=3。  
每个圆圈显示的是核心对象的ϵ-邻域范围，x1是核心对象，x2由x1密度直达(在圆圈内的都是核心对象密度直达的)，x3由x1密度可达，x3和x4是密度相连。   
可以认为，DBSCAN算法将所有点分为三类：核心点、非核心点(边界点)、异常点。(边界点在领域内但周围样本点数量不达标，异常点不在领域内)  

- 簇：由密度可达关系导出的最大的密度相连样本集合。   
#### (1.2) 实现过程：  
　　　　这个DBSCAN的簇里面可以有一个或者多个核心对象。如果只有一个核心对象，则簇里其他的非核心对象样本都在这个核心对象的ϵ-邻域里；如果有多个核心对象，则簇里的任意一个核心对象的ϵ-邻域中一定有一个其他的核心对象，否则这两个核心对象无法密度可达。这些核心对象的ϵ-邻域里所有的样本的集合组成的一个DBSCAN聚类簇。

　　　　那么怎么才能找到这样的簇样本集合呢？DBSCAN使用的方法很简单，它任意选择一个没有类别的核心对象作为种子，然后找到所有这个核心对象能够密度可达的样本集合，即为一个聚类簇。接着继续选择另一个没有类别的核心对象去寻找密度可达的样本集合，这样就得到另一个聚类簇。一直运行到所有核心对象都有类别为止。
可以以传销的方式去理解整个过程：
(1) 首先，在整个数据集里随机地选取某个点A，然后根据我们设定的标准（半径以及圈内数量），评判A是否能开展一个新簇。假设半径为2、最小数量为4，如果点A达到以上标准（满足条件，A就是一个核心对象），那么可以以它为基础开展一个新簇。  
(2) 假设点A圈住了5个点：B C D E F，现在这5个点就要去发展下线了。同样是以上述标准，去看他们能否发展下线。  
(3) 不断重复步骤（2），直至没有符合标准的下线了。这就构成了第一个簇C1。  
(4) 除了C1中的点，随机选取某个点，看它能否像点A一样去发展一个新簇，重复（1）（2）（3）步骤，不断去找新簇。  
(5) 直到找不到新簇了，没纳进新簇的就是异常值点。    
### 二. 算法优缺点：
#### (2.1) 优点：  
- 不需要事先给定一个K值（KMmeans需要事先确定一个K值）    
- 适用于任意形状的稠密数据集，不单单是凸数据集（KMmeans仅对凸数据集聚类效果好）    
- 能够有效的发现噪声点、异常值，可用于异常值检测
- 初始值的选择对聚类结果无影响，聚类结果几乎不依赖于结点遍历顺序，没有偏倚（初始质心的选择影响KMmeans迭代速度及效果）
>
#### (2.2) 缺点：  
- 当聚类的密度不同或或类间的距离相差很大时，DBSCAN的性能会不如其他算法   
- 算法涉及两个参数：距离阈值ϵ，邻域样本数阈值MinPts。需要联合调参，不同的参数组合对最后的聚类效果有较大影响
- 面对高维数据容易溢出，算起来慢（可以先做降维）
- 该算法的运行速度要比 KMeans 算法慢一些
>
### 三. k值确定：
#### (3.1) 个人需求/经验  
比如，做客户分层，你想分成4部分，那么k值就取你想要的4。
>
#### (3.2) 手肘法Elbow method——看图辨别拐点   

- (3.2.1) SSE参数解释：  
得很缓慢时，就认为进一步增大聚类数效果也聚类效果也没有太明显的变化。关注斜率最大处，一个明显的“肘点”就是最佳聚类数目。
- (3.2.3) 举例SSE图表示：
![](https://pic2.zhimg.com/v2-25b396108e9b5da6094c2097888f2251_b.png)   
此时，选k=3。  
>
#### (3.3) Gap statistic   

>
#### (3.4) 轮廓系数Silhouette Coefficient

>
#### (3.5) Calinski-Harabasz Index 即(CH)指标  

>
### 四. 举栗子：
下面用sklearn的make_blobs方法来生成聚类算法的测试数据：  

![](https://ftp.bmp.ovh/imgs/2020/12/169871e487d9afb4.png)
(4.1) 手肘法



参考资料：  
西瓜书
[B站视频](https://www.bilibili.com/video/BV1j4411H7xv?p=1)  
大佬Blog,[(1)](https://www.cnblogs.com/pinard/p/6208966.html)、知乎多个回答
聚类效果可视化体验(某位外国大佬写的体验网站)[地址](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)  
![](https://ftp.bmp.ovh/imgs/2020/12/1187054a9d252826.png)  

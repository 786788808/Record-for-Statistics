### 与GBDT的区别：
- 传统的 GBDT 模型以CART决策树作为基学习器，而 XGBoost 还支持线性分类器，可以是L1和L2正则化的逻辑回归模型和线性回归模型，提高了模型的应用范围。  
- 传统的额 GBDT 模型在优化时只用到损失函数的一阶导数信息，而 XGBoost 同时用到一阶和二阶导数信息，可以加快优化速度。
- XGBoost 在损失函数里加入了正则项，用于控制模型的复杂度。也因为正则项的存在，从权衡偏差和方差角度来看，相比GBDT算法，其降低了方差，防止模型过拟合，使得模型有更好的泛化能力。 
- 支持并行处理。不是像Bagging里面的弱学习器之间并行处理，而是      
- 能够自动处理缺失值
- 在生成决策树的过程中支持列抽样(借鉴随机森林对特征随机抽取的思想)，防止过拟合，且减少计算量。  



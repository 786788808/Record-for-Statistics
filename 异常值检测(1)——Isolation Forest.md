### 背景：    
在建模前，需要做异常值检测(离群点检测)。一般的，用正态分布的三个标准差法则、箱线图是最基础的方法。但是面临高维数据的时候，仅从一维的角度考虑还略有欠缺。    

### 一. 异常值检测应用场景：  
- 特征工程过程中要剔除异常值，不然要影响建模效果(比如，KMeans算法)  
- 对没有标记输出的特征数据做筛选，找出异常值
- 监督学习中，做二分类时，如果类别失衡，可以考虑用非监督的异常值检测算法来做(比如，检测患者是否患肺癌、判断用户是否存在欺诈行为)

### 二. 方法一：Isolation Forest 算法
是一种无监督的异常检测算法，主要是利用集成学习的思路来做异常点检测，面对大数据量，该算法有较好的表现。    
优点：
算法具有线性时间复杂度，处理海量数据的时候表现较好。

缺点：
面对高维数据，处理能力欠缺，需要先做降维或者用其他方法，比如 one class SVM
如果训练样本中异常值较多，会违背算法的基本假设，导致检测效果不好

- 如果一个数据点 得分 s 很接近 1，那么可以认为是异常点
- 如果一个数据点 得分 s 远远小于 0.5，那么可以被认为是正常点
- 如果所有的数据点得分 s 约等于 0.5，那么所有的样本可能没有明显的异常点存在

predict(X)：  
返回值：+1 表示正常样本， -1表示异常样本。
decision_function(X)：  
返回样本的异常评分。 值越小表示越有可能是异常样本。
举栗子：  


Isolation Forest 算法主要有两个参数：一个是二叉树的个数；另一个是训练单棵 iTree 时候抽取样本的数目。实验表明，当设定为 100
棵树，抽样样本数为 256 条时候，IF 在大多数情况下就已经可以取得不错的效果。这也体现了算法的简单、高效。

### 三. 方法二：one calss SVM 算法

### 四. 方法三：DBSCAN 算法
直接去看DBSCAN那篇，DBSCAN的主要目的是做聚类，而异常值检测有点附赠礼品的意思。DBSCAN 算法基于密度将数据点聚类，然后将所有的数据点划分为：核心对象、边界点、异常值点。  
在建模前，需要定义： 距离 ℇ、邻域内包含的最小点数 Minpts  
- 核心点：在距离 ℇ 内至少具有最小包含点数（Minpts）的数据点
- 边界点： 核心点的距离ℇ内邻近点，但包含的点数小于最小包含点数（Minpts）
- 异常值点： 非核心点、非边界点，两个条件都满足不了的点
